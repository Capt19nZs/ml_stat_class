{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.0"
    },
    "colab": {
      "name": "HW_4.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcnoa8jdWXTb",
        "colab_type": "text"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFghjoOyWXTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a9fqcW4WXTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e36ce8b6-03ee-4d26-b3f5-ac0abc506fc6"
      },
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "DATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
        "\n",
        "path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
        "with np.load(path) as data:\n",
        "  X_train = data['x_train']\n",
        "  y_train = data['y_train']\n",
        "  X_test = data['x_test']\n",
        "  y_test = data['y_test']\n",
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hnldvqhWXTo",
        "colab_type": "text"
      },
      "source": [
        "## The data is prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVWFK_ALWXTp",
        "colab_type": "text"
      },
      "source": [
        "1 Estimate MNIST SGDClassifier to distinguish digits 3 and 5 from other digits. Report average precision rate when the recall = 75% (you can round up the recall value up to the 3rd digit). Use cv = 3. Use random_state = 42."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lHLqc08WXTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDlleTn0WXTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get fit statistics\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf8Dx3HmWXTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUxt2LT_WXT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5jdu3SFWXT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plGbIaFFWXT5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iooIqxMnWXT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b__x6rgSWXT-",
        "colab_type": "text"
      },
      "source": [
        "## Problem 2 \n",
        "Plot Precision-recall curve for the fit statistics from the problem 1 bounding precision between 60% and 90%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYdv_YJuWXT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv5RMB0iWXUA",
        "colab_type": "text"
      },
      "source": [
        "## Problem 3 \n",
        "What is the threshold that maximizes precision + recall from the previous problem? Report the threshold and maximum precision and recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJme-1ipWXUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ugY4-NAWXUD",
        "colab_type": "text"
      },
      "source": [
        "**Load Titanic Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzCj-RsxWXUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import functools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
        "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
        "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(train_file_path)\n",
        "train_data.head()\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJuPBhvPWXUH",
        "colab_type": "text"
      },
      "source": [
        "The attributes have the following meaning:\n",
        "\n",
        "Survived: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
        "Pclass: passenger class.\n",
        "Name, Sex, Age: self-explanatory\n",
        "SibSp: how many siblings & spouses of the passenger aboard the Titanic.\n",
        "Parch: how many children & parents of the passenger aboard the Titanic.\n",
        "Ticket: ticket id\n",
        "Fare: price paid (in pounds)\n",
        "Cabin: passenger's cabin number\n",
        "Embarked: where the passenger embarked the Titanic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMaHAoVJWXUI",
        "colab_type": "text"
      },
      "source": [
        "## Problem 4\n",
        "Build a pipeline to impute missing data for [\"age\", \"n_siblings_spouses\", \"parch\", \"fare\"]. Also impute missing categorical variables [\"class\", 'deck', embark_town'] and convert them into indicator variables. Merge them together, so that final data set have 7 features. Create vectors for training and testing data. Use \"Survived\" as a predictor and the rest of the variables as features. Transform both training and testing data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo5-0wflWXUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer as Imputer\n",
        "\n",
        "# A class to select numerical or categorical columns \n",
        "# since Scikit-Learn doesn't handle DataFrames yet   "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hwqSy1AWXUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder \n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msPAu1y7WXUL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import FeatureUnion\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA86JUGKWXUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "bSCty2AsWXUO",
        "colab_type": "text"
      },
      "source": [
        "## Problem 5\n",
        " estimate data predicting survival using SDG classifier (loss='log') and logit to train model on the training data and test on testing data. Report ROC AUC score for each model. Set random_state = 42. method=\"predict_proba\", to make results comparable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huAsECWTWXUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFtDjZyv3qUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FiAavCDWXUQ",
        "colab_type": "text"
      },
      "source": [
        "Random forest model performs better in predicting survival from Titanic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPqxWDv9WXUR",
        "colab_type": "text"
      },
      "source": [
        "## Problem 6\n",
        "Repeat the same exerise as before, but instead of predicting probability of survival predict class, i.e., don't use  method=\"predict_proba\". Which method is better? How do you explain the difference between the results?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CigyncpNWXUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX90t_GAWXUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0gb_lXkWXUT",
        "colab_type": "text"
      },
      "source": [
        "Answer: The relative ranking is the same: Logistic performs better. However, both methods perform poorly. When predicting probabilities weak probability of survival would have a score of 0.6, so if this prediction would be erroneous the error is just (0.6 -0) = 0.6. However, if we are predicting classes, then the probability of 0.6 would be classified as survived, then the error would be higher (1 - 0) = 1. This difference does not affect predictions with very high or very low probabilities, as in these cases the difference between probabilities and classes would be very small.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGV_hlvlWXUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jWQzVZaWXUV",
        "colab_type": "text"
      },
      "source": [
        "## Problem 7\n",
        "Use Titanic data and model estimated in the problem 6 using logit. Show confusion matrix for each model. Describe the most typical error each model has. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIYBSh6nWXUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CSTVl4bWXUX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}